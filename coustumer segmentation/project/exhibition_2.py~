# -*- coding: utf-8 -*-
"""exhibition 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IwF0OnHNL2cbVZC435dQVbRavAJw0S1m
"""

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, normalize
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score 
import sys
data = pd.read_csv('./Mall_Customers.csv')
data=pd.DataFrame(data)

data[34:78]

data=data.drop(columns=['Gender'])
bar=data
copy=data

"""Applying Scaler and PAC to normalize our data to apply algorithm."""

scaler = StandardScaler()
X_scaled = scaler.fit_transform(data)
X_normalized = normalize(X_scaled)
  
# Converting the numpy array into a pandas DataFrame
X_normalized = pd.DataFrame(X_normalized)
  
# Reducing the dimensions of the data
pca = PCA(n_components = 2)
X_principal = pca.fit_transform(X_normalized)
data = pd.DataFrame(X_principal)
data.columns = ['P1', 'P2']
  
data.head()

"""Applying k-means ALgorithm."""

'''Age and spending Score'''
X1 = data
inertia = []
for n in range(1 , 11):
    algorithm = (KMeans(n_clusters = n ,init='k-means++', n_init = 10 ,max_iter=300, 
                        tol=0.0001,  random_state= 111  , algorithm='elkan') )
    algorithm.fit(X1)
    inertia.append(algorithm.inertia_)

inertia

algorithm_kmeans= (KMeans(n_clusters = 3 ,init='k-means++', n_init = 10 ,max_iter=300, 
                        tol=0.0001,  random_state= 111  , algorithm='elkan') )
algorithm_kmeans.fit(X1)
labels1 = algorithm_kmeans.labels_
centroids1 = algorithm_kmeans.cluster_centers_

h = 0.02
x_min, x_max = X1['P1'].min() - 1, X1['P1'].max() + 1
y_min, y_max = X1['P2'].min() - 1, X1['P2'].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
smallData = pd.DataFrame(np.c_[xx.ravel(), yy.ravel()], columns = ['P1', 'P2'])
Z = algorithm.predict(smallData)

plt.figure(1 , figsize = (15 , 7) )
plt.clf()
Z = Z.reshape(xx.shape)
plt.imshow(Z , interpolation='nearest', 
           extent=(xx.min(), xx.max(), yy.min(), yy.max()),
           cmap = plt.cm.Pastel2, aspect = 'auto', origin='lower')

plt.scatter( x = 'P1' ,y = 'P2' , data = data , c = labels1 , 
            s = 200 )
plt.scatter(x = centroids1[: , 0] , y =  centroids1[: , 1] , s = 300 , c = 'red' , alpha = 0.5)
plt.ylabel('Spending Score (1-100)') , plt.xlabel('Age')
plt.show()

"""Applying Spectral clutering with rbf affinity."""

from sklearn.cluster import SpectralClustering
sc=SpectralClustering(n_clusters=3)
sc=sc.fit_predict(X1)

sc

X1

colors={}
colors[0]='b'
colors[1]='y'
colors[2]='r'
cvec=[colors[i] for i in sc]
b=plt.scatter(x='P1',y='P2',color='b')
y=plt.scatter(x='P1',y='P2',color='y')
r=plt.scatter(x='P1',y='P2',color='r')

plt.figure(figsize =(9,9))
plt.scatter(x='P1',y='P2',data=X1,c=cvec)
plt.xlabel('Age'),plt.ylabel('Spending Score')
plt.legend((b,y,r),('label 1','label 2','label 3'))
plt.show()

"""Applying spectral clustering with nearesst-neighbour affinity."""

nearest=SpectralClustering(n_clusters=3,affinity='nearest_neighbors')
nearest_model=nearest.fit_predict(X1)

colors={}
colors[0]='b'
colors[1]='y'
colors[2]='r'
cvec=[colors[i] for i in nearest_model]


plt.figure(figsize =(9,9))
plt.scatter(x='P1',y='P2',data=X1,c=cvec)
plt.xlabel('Age'),plt.ylabel('Spending Score')
plt.legend((b,y,r),('label 1','label 2','label 3'))
plt.show()

"""Comparing the three algorithms."""

affininty=['rbf','nearest-neighbours','kmeans']
s_scores=[]
s_scores.append(silhouette_score(bar,sc))
s_scores.append(silhouette_score(bar,nearest_model))
s_scores.append(silhouette_score(bar,labels1))

print(s_scores)

plt.bar(affininty,s_scores,color='lavender')
plt.xlabel('affininty'),plt.ylabel('silhouette_score')
plt.title("comparison of algoeithms")
plt.show()

"""Since all the algorithms are in close proximity from each other and k-means and specteral clusterin with affinity towards nearest neighbour are identical, we preffred k means, when training an algorith with preset data base."""

labels1

labeled_data=copy
labeled_data['Group']=labels1

labeled_data.head()

"""Implementing a new csv file which is generated on hourly basis, by an  automation code, in your app, (in this case we are manually putting itm through data obtained via google form, because of lack of resources to create an application.

updated_data.csv is file which can be written by file manipulation using python in your app, but we are downloading it, and putting it manually in.

It can also be programed via a simple automation scrip to download, csv records if they go over 50 in number and implemrnt in our model.


Below section of code can be used directly into an aaplication
"""
def algo:
  new_data=pd.read_csv('updated_data.csv')
  new_data=pd.DataFrame(new_data)
  algo=algorithm_kmeans
  new_data.drop(columns=['Gender'],inplace=True)
  base_count=len(copy['CustomerID'])
  new_data['CustomerID']=[base_count+i-1 for i in new_data['CustomerID']]
  new_data

  copy.drop(columns=['Group'],inplace=True)
  copy

  reinforcement_data=copy
  reinforcement_data.append(new_data,ignore_index=True)
  reinforcement_data

"""Applying vector and pca analysis on newly updated data"""

  scaler = StandardScaler()
  X_scaled = scaler.fit_transform(reinforcement_data)
  X_normalized = normalize(X_scaled)
  
# Converting the numpy array into a pandas DataFrame
  X_normalized = pd.DataFrame(X_normalized)
  
# Reducing the dimensions of the data
  pca = PCA(n_components = 2)
  X_principal = pca.fit_transform(X_normalized)
  new_pca = pd.DataFrame(X_principal)
  new_pca.columns = ['P1', 'P2']
  
  new_pca.head()

  algo.fit(new_pca)
  newlabels=algo.labels_
  reinforcement_data.shape

  reinforcement_data['predictions']=newlabels
  reinforcement_data

  correct=[]
  incorrect=[]
  import random 
  for i in reinforcemt_data[base_count:]:
    z=random.randint(0,1)
    if i['feedback']==i['predictions'] and z==1:
      correct.append(i)
    elif i['feedback']!=i['predictions'] and z==1:
      incorrect.append(i)

  algorithm_kmeans=algo
